{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read Text_Ham_Spam_Calssification csv file\n",
    "Df = pd.read_csv(\"Text_Ham_Spam_Calssification.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5026, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows and columns in Dataframe\n",
    "Df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for yourself on your way home. I can't even move. Pain is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  \\\n",
       "0      ham   \n",
       "1      ham   \n",
       "2     spam   \n",
       "3      ham   \n",
       "4      ham   \n",
       "\n",
       "                                                                                               Message  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4  Your gonna have to pick up a $1 burger for yourself on your way home. I can't even move. Pain is...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category Message\n",
       "5021      NaN     NaN\n",
       "5022      NaN     NaN\n",
       "5023      NaN     NaN\n",
       "5024      NaN     NaN\n",
       "5025      NaN     NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.tail()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Filtering the records, where rows in both columns are not null (columns :: Category and Message)\n",
    "# Could see 1790 messages are not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1 = Df[0:1790]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Could see 3235 records having null values (for both columns :: Category and Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category    3235\n",
       "Message     3235\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2 = Df[1790:]\n",
    "df2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category    65\n",
       "Message      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of 1790 messages, 65 messages got categories null(Missing Categories) and I am considering this as my test data to predict categories for these 65 messages.\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "Missing_categories = df1[df1[\"Category\"].isnull()]\n",
    "Missing_categories.to_csv(\"Test_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm at work. Please call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Then u drive lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ard 515 like dat. Y?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tell me they're female :V how're you throwing in? We're deciding what all to get now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EASTENDERS TV Quiz. What FLOWER does DOT compare herself to? D= VIOLET E= TULIP F= LILY txt D E ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ya tel, wats ur problem..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No. 1 Nokia Tone 4 ur mob every week! Just txt NOK to 87021. 1st Tone FREE ! so get txtin now an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i dnt wnt to tlk wid u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We spend our days waiting for the ideal path to appear in front of us.. But what we forget is.. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Its ok my arm is feeling weak cuz i got a shot so we can go another time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category  \\\n",
       "1000      NaN   \n",
       "1001      NaN   \n",
       "1002      NaN   \n",
       "1003      NaN   \n",
       "1004      NaN   \n",
       "...       ...   \n",
       "1323      NaN   \n",
       "1324      NaN   \n",
       "1325      NaN   \n",
       "1326      NaN   \n",
       "1327      NaN   \n",
       "\n",
       "                                                                                                  Message  \n",
       "1000                                                                             I'm at work. Please call  \n",
       "1001                                                                                    Then u drive lor.  \n",
       "1002                                                                                 Ard 515 like dat. Y?  \n",
       "1003                 Tell me they're female :V how're you throwing in? We're deciding what all to get now  \n",
       "1004  EASTENDERS TV Quiz. What FLOWER does DOT compare herself to? D= VIOLET E= TULIP F= LILY txt D E ...  \n",
       "...                                                                                                   ...  \n",
       "1323                                                                            Ya tel, wats ur problem..  \n",
       "1324  No. 1 Nokia Tone 4 ur mob every week! Just txt NOK to 87021. 1st Tone FREE ! so get txtin now an...  \n",
       "1325                                                                               i dnt wnt to tlk wid u  \n",
       "1326  We spend our days waiting for the ideal path to appear in front of us.. But what we forget is.. ...  \n",
       "1327                             Its ok my arm is feeling weak cuz i got a shot so we can go another time  \n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Missing_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1785</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah. I got a list with only u and Joanna if I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1786</td>\n",
       "      <td>ham</td>\n",
       "      <td>I am in your office na.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1787</td>\n",
       "      <td>ham</td>\n",
       "      <td>Are you comingdown later?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1788</td>\n",
       "      <td>ham</td>\n",
       "      <td>Super da:)good replacement for murali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1789</td>\n",
       "      <td>ham</td>\n",
       "      <td>Da is good good player.why he is unsold.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1725 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Your gonna have to pick up a $1 burger for you...\n",
       "...       ...                                                ...\n",
       "1785      ham  Yeah. I got a list with only u and Joanna if I...\n",
       "1786      ham                            I am in your office na.\n",
       "1787      ham                          Are you comingdown later?\n",
       "1788      ham              Super da:)good replacement for murali\n",
       "1789      ham           Da is good good player.why he is unsold.\n",
       "\n",
       "[1725 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe containing only those rows which contain category HAM or SPAM are not null\n",
    "df1.drop(Missing_categories.index, inplace = True) \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting messages to embeddings (Words to vectors) using Spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "import time\n",
    "from datetime import timedelta\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Pre-trained Model :: 'en_vectors_web_lg'\n",
    "nlp = spacy.load('en_vectors_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.863188\n",
      "spam    0.136812\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Could see the data is imbalanced where ham as 80 percentage and spam as 13 percentage \n",
    "# We need to balance them for that I am using Smoting technique\n",
    "print(df1['Category'].value_counts(normalize = True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the text by doing the following operations.\n",
    "\n",
    "# Define a list of punctuation marks\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Code to replace punctuation marks with whitespace \n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, ' ')\n",
    "    return x\n",
    "\n",
    "# Remove URL's from df1 and Missing_categories datasets\n",
    "df1['clean_Message'] = df1['Message'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "Missing_categories['clean_Message'] = Missing_categories['Message'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "# Remove user handles @\n",
    "df1['clean_Message'] = df1['clean_Message'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
    "Missing_categories['clean_Message'] = Missing_categories['clean_Message'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
    "\n",
    "# Remove punctuation marks\n",
    "df1['clean_Message'] = df1['clean_Message'].apply(lambda x: clean_text(x))\n",
    "Missing_categories['clean_Message'] = Missing_categories['clean_Message'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Convert text to lowercase\n",
    "df1['clean_Message'] = df1['clean_Message'].str.lower()\n",
    "Missing_categories['clean_Message'] = Missing_categories['clean_Message'].str.lower()\n",
    "\n",
    "# Remove numbers\n",
    "df1['clean_Message'] = df1['clean_Message'].str.replace(\"[0-9]\", \" \")\n",
    "Missing_categories['clean_Message'] = Missing_categories['clean_Message'].str.replace(\"[0-9]\", \" \")\n",
    "\n",
    "# Remove whitespaces\n",
    "df1['clean_Message'] = df1['clean_Message'].apply(lambda x:' '.join(x.split()))\n",
    "Missing_categories['clean_Message'] = Missing_categories['clean_Message'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>clean_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>spam</td>\n",
       "      <td>SMS. ac Blind Date 4U!: Rodds1 is 21/m from Aberdeen, United Kingdom. Check Him out http://img. ...</td>\n",
       "      <td>sms ac blind date u rodds is m from aberdeen united kingdom check him out sms ac w icmb cktz r n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yup... From what i remb... I think should be can book...</td>\n",
       "      <td>yup from what i remb i think should be can book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>ham</td>\n",
       "      <td>Jos ask if u wana meet up?</td>\n",
       "      <td>jos ask if u wana meet up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>ham</td>\n",
       "      <td>Lol yes. Our friendship is hanging on a thread cause u won't buy stuff.</td>\n",
       "      <td>lol yes our friendship is hanging on a thread cause u won t buy stuff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category  \\\n",
       "249     spam   \n",
       "250      ham   \n",
       "251      ham   \n",
       "252      ham   \n",
       "\n",
       "                                                                                                 Message  \\\n",
       "249  SMS. ac Blind Date 4U!: Rodds1 is 21/m from Aberdeen, United Kingdom. Check Him out http://img. ...   \n",
       "250                                             Yup... From what i remb... I think should be can book...   \n",
       "251                                                                           Jos ask if u wana meet up?   \n",
       "252                              Lol yes. Our friendship is hanging on a thread cause u won't buy stuff.   \n",
       "\n",
       "                                                                                           clean_Message  \n",
       "249  sms ac blind date u rodds is m from aberdeen united kingdom check him out sms ac w icmb cktz r n...  \n",
       "250                                                      yup from what i remb i think should be can book  \n",
       "251                                                                            jos ask if u wana meet up  \n",
       "252                                lol yes our friendship is hanging on a thread cause u won t buy stuff  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing the Original Message and Cleaned message\n",
    "df1[249:253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category  \\\n",
      "1785      ham   \n",
      "1786      ham   \n",
      "1787      ham   \n",
      "1788      ham   \n",
      "1789      ham   \n",
      "\n",
      "                                                                          Message  \\\n",
      "1785  Yeah. I got a list with only u and Joanna if I'm feeling really anti social   \n",
      "1786                                                      I am in your office na.   \n",
      "1787                                                    Are you comingdown later?   \n",
      "1788                                        Super da:)good replacement for murali   \n",
      "1789                                     Da is good good player.why he is unsold.   \n",
      "\n",
      "                                                                clean_Message  \n",
      "1785  yes i get a list with only u and joanna if i be feel really anti social  \n",
      "1786                                                   i be in your office na  \n",
      "1787                                                   be you comingdown late  \n",
      "1788                                     super da good replacement for murali  \n",
      "1789                                  da be good good player why he be unsold  \n",
      "     Category  \\\n",
      "1323      NaN   \n",
      "1324      NaN   \n",
      "1325      NaN   \n",
      "1326      NaN   \n",
      "1327      NaN   \n",
      "\n",
      "                                                                                                  Message  \\\n",
      "1323                                                                            Ya tel, wats ur problem..   \n",
      "1324  No. 1 Nokia Tone 4 ur mob every week! Just txt NOK to 87021. 1st Tone FREE ! so get txtin now an...   \n",
      "1325                                                                               i dnt wnt to tlk wid u   \n",
      "1326  We spend our days waiting for the ideal path to appear in front of us.. But what we forget is.. ...   \n",
      "1327                             Its ok my arm is feeling weak cuz i got a shot so we can go another time   \n",
      "\n",
      "                                                                                            clean_Message  \n",
      "1323                                                                               you tel wat ur problem  \n",
      "1324  no nokia tone ur mob every week just txt nok to st tone free so get txtin now and tell ur friend...  \n",
      "1325                                                                               i dnt wnt to tlk wid u  \n",
      "1326  we spend our day wait for the ideal path to appear in front of us but what we forget be path be ...  \n",
      "1327                             its okay my arm be feel weak cuz i get a shoot so we can go another time  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Function to lemmatize the tokens to their basic forms to normalize the message\n",
    "\n",
    "\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "\n",
    "\n",
    "# Lemmatise the tokens\n",
    "df1['clean_Message'] = lemmatization(df1['clean_Message'])\n",
    "df1['clean_Message'] = df1['clean_Message'].str.replace(\"-PRON-\", \"\")\n",
    "Missing_categories['clean_Message'] = lemmatization(Missing_categories['clean_Message'])\n",
    "Missing_categories['clean_Message'] = Missing_categories['clean_Message'].str.replace(\"-PRON-\", \"\")\n",
    "\n",
    "print(df1.tail())\n",
    "\n",
    "print(Missing_categories.tail())\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 300) (65, 300)\n"
     ]
    }
   ],
   "source": [
    "# Convert cleaned tweets into Spacy word vectors\n",
    "# The model returns 300-dimensional embeddings\n",
    "tweets = df1['clean_Message']\n",
    "word_vec = [nlp(word).vector for word in tweets]\n",
    "X_tr = np.array(word_vec)\n",
    "\n",
    "Missing_categories_tweets = Missing_categories['clean_Message']\n",
    "Missing_categories_word_vec = [nlp(word).vector for word in Missing_categories_tweets]\n",
    "X_te = np.array(Missing_categories_word_vec)\n",
    "\n",
    "print(X_tr.shape, X_te.shape)\n",
    "\n",
    "\n",
    "# Save Spacy_train_new as pickle file to resue later\n",
    "pickle_out = open(\"Spacy_train.pickle\",\"wb\")\n",
    "pickle.dump(X_tr, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "# Save Spacy_train_new as pickle file to resue later\n",
    "pickle_out = open(\"Spacy_test.pickle\",\"wb\")\n",
    "pickle.dump(X_te, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 300)\n",
      "ham     1489\n",
      "spam     236\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# sklearn_ML_models_with_embeddings\n",
    "# Load variation of word embeddings from Spacy.\n",
    "pickle_in = open(\"Spacy_train.pickle\",\"rb\")      \n",
    "X = pickle.load(pickle_in)\n",
    "print(X.shape)\n",
    "\n",
    "# Observe the distribution of positive and negative tweets\n",
    "print(df1['Category'].value_counts())\n",
    "\n",
    "# Assign targets to y variable\n",
    "y = df1['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552,)\n",
      "(1552, 300)\n",
      "(173, 300)\n",
      "(173,)\n",
      "ham     0.86018\n",
      "spam    0.13982\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the training dataset into train and test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "# We could see the imbalance in the target varaible , So to balance we are using Smoting technique below.\n",
    "print(y_train.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "X_train_sm , y_train_sm = sm.fit_sample(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam    0.5\n",
      "ham     0.5\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train_sm.shape\n",
    "print(y_train_sm.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'spam' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'spam' 'spam']\n"
     ]
    }
   ],
   "source": [
    "# Applying Random forest classifier for Ham Spam classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# we can do grid x=search to find out the best parameters , but my system is taking a lot of time to find those.\n",
    "# So assuming the best parameters by myself as of now.\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [6,10,25],\n",
    "#     'max_features': [15,25,30],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': [8, 12],\n",
    "#     'n_estimators': [100, 150, 350]\n",
    "# }\n",
    "# # Create a based model\n",
    "# rf = RandomForestClassifier()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "#                           cv = 3, n_jobs = -1, verbose = 2)\n",
    "model = RandomForestClassifier(n_estimators=300,max_depth = 6,max_features=20)\n",
    "model.fit(X_train_sm, y_train_sm)\n",
    "predictions = model.predict(X_test)\n",
    "print((predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[152   2]\n",
      " [  0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.99      0.99       154\n",
      "        spam       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.99       173\n",
      "   macro avg       0.95      0.99      0.97       173\n",
      "weighted avg       0.99      0.99      0.99       173\n",
      "\n",
      "0.9884393063583815\n"
     ]
    }
   ],
   "source": [
    "# Import metrics to check the accuracy for the predictions made\n",
    "from sklearn import metrics\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we could see above , we got 2 False Positives using Random forest calssifier after balancing the target varaible.\n",
    "# Without Blancing the target varaibale I could see more False positives and Few False Negatives.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 300)\n",
      "['ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'spam' 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Loading corresponding test message embeddings as loaded for the training dataset\n",
    "pickle_in = open(\"Spacy_test.pickle\",\"rb\")\n",
    "test_X = pickle.load(pickle_in)\n",
    "print(test_X.shape)\n",
    "\n",
    "# Making predictions using trained model for the test dataset for final submission \n",
    "test_predictions = model.predict(test_X)\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Category_ham_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>I'm at work. Please call</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>Then u drive lor.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1002</td>\n",
       "      <td>Ard 515 like dat. Y?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1003</td>\n",
       "      <td>Tell me they're female :V how're you throwing in? We're deciding what all to get now</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1004</td>\n",
       "      <td>EASTENDERS TV Quiz. What FLOWER does DOT compare herself to? D= VIOLET E= TULIP F= LILY txt D E ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>Ya tel, wats ur problem..</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1324</td>\n",
       "      <td>No. 1 Nokia Tone 4 ur mob every week! Just txt NOK to 87021. 1st Tone FREE ! so get txtin now an...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>i dnt wnt to tlk wid u</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1326</td>\n",
       "      <td>We spend our days waiting for the ideal path to appear in front of us.. But what we forget is.. ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1327</td>\n",
       "      <td>Its ok my arm is feeling weak cuz i got a shot so we can go another time</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  Message  \\\n",
       "1000                                                                             I'm at work. Please call   \n",
       "1001                                                                                    Then u drive lor.   \n",
       "1002                                                                                 Ard 515 like dat. Y?   \n",
       "1003                 Tell me they're female :V how're you throwing in? We're deciding what all to get now   \n",
       "1004  EASTENDERS TV Quiz. What FLOWER does DOT compare herself to? D= VIOLET E= TULIP F= LILY txt D E ...   \n",
       "...                                                                                                   ...   \n",
       "1323                                                                            Ya tel, wats ur problem..   \n",
       "1324  No. 1 Nokia Tone 4 ur mob every week! Just txt NOK to 87021. 1st Tone FREE ! so get txtin now an...   \n",
       "1325                                                                               i dnt wnt to tlk wid u   \n",
       "1326  We spend our days waiting for the ideal path to appear in front of us.. But what we forget is.. ...   \n",
       "1327                             Its ok my arm is feeling weak cuz i got a shot so we can go another time   \n",
       "\n",
       "     Category_ham_spam  \n",
       "1000               ham  \n",
       "1001               ham  \n",
       "1002               ham  \n",
       "1003               ham  \n",
       "1004              spam  \n",
       "...                ...  \n",
       "1323               ham  \n",
       "1324              spam  \n",
       "1325               ham  \n",
       "1326               ham  \n",
       "1327               ham  \n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally filling the missing categories of 65 messages with spam and ham (Predictions)\n",
    "Missing_categories[\"Category_ham_spam\"] = test_predictions\n",
    "final_predictions = Missing_categories[[\"Message\",\"Category_ham_spam\"]]\n",
    "final_predictions.to_csv(\"final_predictions.csv\",index = False)\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam'\n",
      " 'spam' 'ham' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'spam' 'spam']\n",
      "[[149   5]\n",
      " [  0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.97      0.98       154\n",
      "        spam       0.79      1.00      0.88        19\n",
      "\n",
      "    accuracy                           0.97       173\n",
      "   macro avg       0.90      0.98      0.93       173\n",
      "weighted avg       0.98      0.97      0.97       173\n",
      "\n",
      "0.9710982658959537\n"
     ]
    }
   ],
   "source": [
    "# Using SVM classifier \n",
    "######### Support Vector Machine #########3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "## Create a pipeline so as to streamline the flow of the data into the ML model\n",
    "text_clf = Pipeline([('clf', LinearSVC())]) #('tfidf', TfidfVectorizer()), ('scaler', MaxAbsScaler())\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train_sm , y_train_sm )\n",
    "\n",
    "# Make predictions\n",
    "predictions = text_clf.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "# Import metrics to check the accuracy and other features of the predictions made\n",
    "from sklearn import metrics\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we could see above 5 False positives using Support Vector Machine ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######classifying spam_ham using tfidf vectors#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Vocabulary for tfidf vectorizer function\n",
    "def flatten_words(list1d, get_unique=False):\n",
    "    qa = [s.split() for s in list1d]\n",
    "    if get_unique:\n",
    "        return sorted(list(set([w for sent in qa for w in sent])))\n",
    "    else:\n",
    "        return [w for sent in qa for w in sent]\n",
    "    \n",
    "\n",
    "all_text = df1['clean_Message'].values.tolist() + Missing_categories['clean_Message'].values.tolist()\n",
    "vocab = flatten_words(all_text, get_unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     1     2     3     4     5     6     7     8     9     ...  3570  \\\n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "   3571  3572  3573  3574  3575  3576  3577  3578  3579  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[3 rows x 3580 columns]\n",
      "(1725, 3580)\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  3570  \\\n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "   3571  3572  3573  3574  3575  3576  3577  3578  3579  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[3 rows x 3580 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', ngram_range=(2,3),vocabulary=vocab)\n",
    "training_matrix = tfidf.fit_transform(df1['clean_Message'])\n",
    "test_matrix = tfidf.fit_transform(Missing_categories['clean_Message'])\n",
    "training  = pd.DataFrame(training_matrix.todense())\n",
    "print(training.head(3))\n",
    "print(training.shape)\n",
    "test = pd.DataFrame(test_matrix.todense())\n",
    "print(test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[154   0]\n",
      " [ 19   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.89      1.00      0.94       154\n",
      "        spam       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.89       173\n",
      "   macro avg       0.45      0.50      0.47       173\n",
      "weighted avg       0.79      0.89      0.84       173\n",
      "\n",
      "0.8901734104046243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the training dataset into train and test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df1['Category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(training, y, test_size=0.1, random_state=42)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "## Create a pipeline so as to streamline the flow of the data into the ML model\n",
    "text_clf = Pipeline([('clf', LinearSVC())]) #('tfidf', TfidfVectorizer()), ('scaler', MaxAbsScaler())\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = text_clf.predict(X_test)\n",
    "# print(predictions)\n",
    "\n",
    "# Import metrics to check the accuracy and other features of the predictions made\n",
    "from sklearn import metrics\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # As we could see above using TFIDF for generating vectors and applying SVM on top of it.\n",
    "# could see 19 False Negatives because deep semantic meaning and ordering of words is not considered in TFIDF vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the given text dataset , using Spacy embeddings and applying Random forest on top of it gave fair results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
